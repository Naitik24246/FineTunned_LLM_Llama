# FineTunned_LLM_Llama

# ğŸ§  Fine-Tuned LLM with Unsloth, Transformers, and TRL

This repository contains the code and training configuration for a fine-tuned Large Language Model (LLM) using the [Unsloth](https://github.com/unslothai/unsloth), [Hugging Face Transformers](https://github.com/huggingface/transformers), and [TRL (Training Reward Learning)](https://github.com/huggingface/trl) libraries.



## ğŸš€ Model Overview

- **Base Model**: "LLaMA-3.2-3B-Instruct"
- **Fine-tuning Method**: LoRA (Low-Rank Adaptation)
- **Libraries Used**:
  - ğŸŒ `unsloth` â€“ Efficient LLM fine-tuning
  - ğŸ¤— `transformers` â€“ Hugging Face ecosystem for model and tokenizer
  - ğŸ§  `trl` â€“ Supervised Fine-Tuning (SFT) training loop



