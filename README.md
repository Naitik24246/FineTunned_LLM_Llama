# FineTunned_LLM_Llama

# 🧠 Fine-Tuned LLM with Unsloth, Transformers, and TRL

This repository contains the code and training configuration for a fine-tuned Large Language Model (LLM) using the [Unsloth](https://github.com/unslothai/unsloth), [Hugging Face Transformers](https://github.com/huggingface/transformers), and [TRL (Training Reward Learning)](https://github.com/huggingface/trl) libraries.



## 🚀 Model Overview

- **Base Model**: "LLaMA-3.2-3B-Instruct"
- **Fine-tuning Method**: LoRA (Low-Rank Adaptation)
- **Libraries Used**:
  - 🐌 `unsloth` – Efficient LLM fine-tuning
  - 🤗 `transformers` – Hugging Face ecosystem for model and tokenizer
  - 🧠 `trl` – Supervised Fine-Tuning (SFT) training loop



